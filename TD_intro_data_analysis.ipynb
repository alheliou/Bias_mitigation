{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alheliou/Bias_mitigation/blob/main/TD_intro_data_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca74db06",
      "metadata": {
        "id": "ca74db06"
      },
      "source": [
        "# TD 1: Fairness notion and data analysis\n",
        "\n",
        "In this first TD we are going to manipulate some data and see the behaviour of the different fairness metrics\n",
        "\n",
        "## Objectives\n",
        "\n",
        "\n",
        " 1. Study the data, the distribution of each feature and its relation to the target.\n",
        "\n",
        " 2. Highlight some bias present in the data\n",
        "\n",
        "\n",
        "## Installation of the environnement\n",
        "\n",
        "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
        "\n",
        "### Colab Settings\n",
        "  The next two cells of code are too execute only once per colab environment\n",
        "\n",
        "\n",
        "#### 1. Python env creation\n",
        "\n",
        "        ```\n",
        "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "\n",
        "#### 2. Download MEPS dataset (for part2) it can take several minutes\n",
        "\n",
        "        ```\n",
        "        ! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
        "        ! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ```\n",
        "\n",
        "  \n",
        "### Local Settings\n",
        "\n",
        "#### 1. Uv installation\n",
        "\n",
        "\n",
        "        https://docs.astral.sh/uv/getting-started/installation/\n",
        "\n",
        "\n",
        "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
        "\n",
        "        Python version 3.12 installation (highly recommended)\n",
        "        `uv python install 3.12`\n",
        "\n",
        "#### 2. R installation (needed for data download/pre-processing only of Part 2)\n",
        "\n",
        "        In the command `Rscript` says 'command not found'\n",
        "\n",
        "        `sudo apt install r-base-core`\n",
        "\n",
        "#### 3. Python env creation\n",
        "\n",
        "        ```\n",
        "        mkdir TD_bias_mitigation\n",
        "        cd TD_bias_mitigation\n",
        "        uv python pin 3.12\n",
        "        uv pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "\n",
        "#### 4. Download MEPS dataset (for part2) it can take several minutes\n",
        "\n",
        "        ```\n",
        "        cd TD_bias_mitigation/.venv/lib/python3.12/site-packages/aif360/data/raw/meps/\n",
        "        Rscript generate_data.R\n",
        "        ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_44TinCUexW",
        "outputId": "a617c3a7-7fb3-4a4d-fb66-143b37071b9c"
      },
      "id": "W_44TinCUexW",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting fairlearn\n",
            "  Downloading fairlearn-0.12.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (5.10.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (6.17.1)\n",
            "Collecting causal-learn\n",
            "  Downloading causal_learn-0.1.4.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting BlackBoxAuditing\n",
            "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.12/dist-packages (1.6.7)\n",
            "Collecting dice-ml\n",
            "  Downloading dice_ml-0.12-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting shapkit\n",
            "  Downloading shapkit-0.0.4-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting aif360[inFairness]\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.12/dist-packages (from fairlearn) (1.16.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.7.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel) (6.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from aif360[inFairness]) (3.10.0)\n",
            "Collecting skorch (from aif360[inFairness])\n",
            "  Downloading skorch-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting inFairness>=0.2.2 (from aif360[inFairness])\n",
            "  Downloading inFairness-0.2.3-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.12/dist-packages (from aif360[AdversarialDebiasing]) (2.19.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from causal-learn) (0.21)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from causal-learn) (0.14.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from causal-learn) (3.5)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from causal-learn) (3.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from causal-learn) (4.67.1)\n",
            "Collecting momentchi2 (from causal-learn)\n",
            "  Downloading momentchi2-0.1.8-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from cvxpy) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from cvxpy) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.12/dist-packages (from cvxpy) (3.2.8)\n",
            "Collecting raiutils>=0.4.0 (from dice-ml)\n",
            "  Downloading raiutils-0.4.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (from dice-ml) (3.0.5)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (from dice-ml) (4.6.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: seaborn>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from shapkit) (0.13.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.12/dist-packages (from clarabel>=0.5.0->cvxpy) (2.0.0)\n",
            "Collecting POT>=0.8.0 (from inFairness>=0.2.2->aif360[inFairness])\n",
            "  Downloading pot-0.9.6.post1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from inFairness>=0.2.2->aif360[inFairness]) (2.8.0+cu126)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.27.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[inFairness]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[inFairness]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[inFairness]) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[inFairness]) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[inFairness]) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360[inFairness]) (3.2.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy) (3.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from osqp>=0.6.2->cvxpy) (1.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.3->fairlearn) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from raiutils>=0.4.0->dice-ml) (2.32.4)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.9.9)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.5.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from skorch->aif360[inFairness]) (0.9.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->causal-learn) (1.0.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost->dice-ml) (2.27.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.45.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.17.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->raiutils>=0.4.0->dice-ml) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->raiutils>=0.4.0->dice-ml) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->raiutils>=0.4.0->dice-ml) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->raiutils>=0.4.0->dice-ml) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi->clarabel>=0.5.0->cvxpy) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->osqp>=0.6.2->cvxpy) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->inFairness>=0.2.2->aif360[inFairness]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.13.1->aif360[AdversarialDebiasing]) (0.1.2)\n",
            "Downloading fairlearn-0.12.0-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.0/240.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading causal_learn-0.1.4.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.0/193.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dice_ml-0.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shapkit-0.0.4-py3-none-any.whl (20 kB)\n",
            "Downloading inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading raiutils-0.4.2-py3-none-any.whl (17 kB)\n",
            "Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading momentchi2-0.1.8-py3-none-any.whl (11 kB)\n",
            "Downloading skorch-1.2.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pot-0.9.6.post1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: BlackBoxAuditing, lime\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394756 sha256=ef3bbc9de9772979b73633711dae5cc5b65dc75be9e1285b6e6c28307beaf119\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/b9/e9/152a447c23f9c30559676a9f4ecee5c7e9a36130d48176555c\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=6fdc0095adba948ae19031aaba958c70475fc92b18dad7b1aedaaeb1eaedabd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built BlackBoxAuditing lime\n",
            "Installing collected packages: jedi, POT, momentchi2, skorch, raiutils, lime, fairlearn, BlackBoxAuditing, aif360, shapkit, inFairness, dice-ml, causal-learn\n",
            "Successfully installed BlackBoxAuditing-0.1.54 POT-0.9.6.post1 aif360-0.6.1 causal-learn-0.1.4.3 dice-ml-0.12 fairlearn-0.12.0 inFairness-0.2.3 jedi-0.19.2 lime-0.2.0.1 momentchi2-0.1.8 raiutils-0.4.2 shapkit-0.0.4 skorch-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OediXLMGVL0_",
        "outputId": "95cd06d6-8f4e-40c3-bf08-f9b7d61b789e"
      },
      "id": "OediXLMGVL0_",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "By using this script you acknowledge the responsibility for reading and\n",
            "abiding by any copyright/usage rules and restrictions as stated on the\n",
            "MEPS web site (https://meps.ahrq.gov/data_stats/data_use.jsp).\n",
            "\n",
            "Continue [y/n]? > y\n",
            "Loading required package: foreign\n",
            "trying URL 'https://meps.ahrq.gov/mepsweb/data_files/pufs/h181ssp.zip'\n",
            "Content type 'application/zip' length 13303652 bytes (12.7 MB)\n",
            "==================================================\n",
            "downloaded 12.7 MB\n",
            "\n",
            "Loading dataframe from file: h181.ssp\n",
            "Exporting dataframe to file: h181.csv\n",
            "trying URL 'https://meps.ahrq.gov/mepsweb/data_files/pufs/h192ssp.zip'\n",
            "Content type 'application/zip' length 15505898 bytes (14.8 MB)\n",
            "==================================================\n",
            "downloaded 14.8 MB\n",
            "\n",
            "Loading dataframe from file: h192.ssp\n",
            "Exporting dataframe to file: h192.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/"
      ],
      "metadata": {
        "id": "h_Lj7wIricJv"
      },
      "id": "h_Lj7wIricJv",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: Diabetes 130-Hospitals\n",
        "\n",
        "\n",
        "https://fairlearn.org/main/api_reference/generated/fairlearn.datasets.fetch_diabetes_hospital.html\n",
        "\n",
        "\n",
        "This dataset contains 101,766 rows, each one corresponding to a patient hospitalized for diabetes for a duration ranging from 1 to 14 days. The data was collected over 10 years and across 130 different hospitals. Each data point has 25 features, including medical and demographic information. The 'readmitted' column indicates whether the patient was readmitted, and if so, whether it was within 30 days or after. This column is further binarized into two other columns: 'readmit_30_days' (True if readmitted within 30 days, False otherwise) and 'readmitted' (True if readmitted, False otherwise).\n",
        "\n",
        "We will use the 'readmit_30_days' column as the label/ground truth.\n",
        "\n",
        "We will simplify the analysis by considering only a subset of 14 provided features:\n",
        "age, gender, race, time_in_hospital, num_lab_procedures, num_procedures, num_medications, number_diagnoses, max_glu_serum, A1Cresult, insulin, had_emergency, had_inpatient_days, had_outpatient_days.\n",
        "\n",
        "## Dataset: Meps\n",
        "\n",
        "We recommend consulting the following pages for a better understanding of the dataset: [MEPSDataset19](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.MEPSDataset19.html) and the [AIF360 tutorial](https://github.com/Trusted-AI/AIF360/blob/main/examples/tutorial_medical_expenditure.ipynb)\n",
        "\n",
        "What you need to have read\n",
        "- **The sensitive attribute is 'RACE' :1 is privileged, 0 is unprivileged** ; It is constructed as follows: 'Whites' (privileged class) defined by the features RACEV2X = 1 (White) and HISPANX = 2 (non Hispanic); 'Non-Whites' that included everyone else.\n",
        "(The features 'RACEV2X', 'HISPANX' etc are removed, and replaced by the 'RACE')\n",
        "- **'UTILIZATION' is the outcome (the label to predict for a ML model) 0 is positive 1 is negative**. It is a binary composite feature, created to measure the total number of trips requiring some sort of medical care, it sum up the following features (that are removed from the data):\n",
        "    * OBTOTV15(16), the number of office based visits\n",
        "    * OPTOTV15(16), the number of outpatient visits\n",
        "    * ERTOT15(16), the number of ER visits\n",
        "    * IPNGTD15(16), the number of inpatient nights\n",
        "    * HHTOTD16, the number of home health visits\n",
        "UTILISATION is set to 1 when te sum is above or equal to 10, else it is set to 0\n",
        "- **The dataset is weighted** The dataset come with an 'instance_weights' attribute that corresponds to the feature perwt15f these weights are supposed to generate estimates that are representative of the United State (US) population in 2015.\n",
        "\n",
        "\n",
        "Summary to remember\n",
        "- **The sensitive attribute is 'RACE' :1 is privileged, 0 is unprivileged**\n",
        "- **'UTILIZATION' is the outcome (the label to predict for a ML model) 0 is positive 1 is negative**\n",
        "- **The dataset is weighted**\n"
      ],
      "metadata": {
        "id": "z1TzkzRFUdp_"
      },
      "id": "z1TzkzRFUdp_"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a3f8114b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3f8114b",
        "outputId": "887c7a28-a8ed-4b3d-8626-1a247a7e1a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  vect_normalized_discounted_cumulative_gain = vmap(\n",
            "/usr/local/lib/python3.12/dist-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
            "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
          ]
        }
      ],
      "source": [
        "# Code to compute fairness metrics using aif360\n",
        "\n",
        "from aif360.sklearn.metrics import *\n",
        "from sklearn.metrics import  balanced_accuracy_score\n",
        "\n",
        "\n",
        "# This method takes lists\n",
        "def get_metrics(\n",
        "    y_true, # list or np.array of truth values\n",
        "    y_pred=None,  # list or np.array of predictions\n",
        "    prot_attr=None, # list or np.array of protected/sensitive attribute values\n",
        "    priv_group=1, # value taken by the privileged group\n",
        "    pos_label=1, # value taken by the positive truth/prediction\n",
        "    sample_weight=None # list or np.array of weights value,\n",
        "):\n",
        "    group_metrics = {}\n",
        "    group_metrics[\"base_rate_truth\"] = base_rate(\n",
        "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    if not y_pred is None:\n",
        "        group_metrics[\"base_rate_preds\"] = base_rate(\n",
        "        y_true=y_pred, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        if len(set(y_pred))>1:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
        "                y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "            )\n",
        "        else:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] =None\n",
        "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"balanced_accuracy_score\"] = balanced_accuracy_score(\n",
        "        y_true=y_true, y_pred=y_pred, sample_weight=sample_weight\n",
        "        )\n",
        "    return group_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d79c25",
      "metadata": {
        "id": "06d79c25"
      },
      "source": [
        "## Part 1: Dataset Diabetes analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4197f02b",
      "metadata": {
        "id": "4197f02b"
      },
      "source": [
        "###  Download and simplify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1dba7fba",
      "metadata": {
        "id": "1dba7fba",
        "outputId": "41401298-558f-4c42-9323-95028beef560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.0.2', '0.12.0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fairlearn\n",
        "np.__version__, fairlearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bcd7d4a9",
      "metadata": {
        "id": "bcd7d4a9"
      },
      "outputs": [],
      "source": [
        "from fairlearn.datasets import fetch_diabetes_hospital\n",
        "dataset = fetch_diabetes_hospital()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "299cae4a",
      "metadata": {
        "id": "299cae4a",
        "outputId": "bd401e37-2116-4b3e-dd80-bf2916800340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 101766 entries, 0 to 101765\n",
            "Data columns (total 15 columns):\n",
            " #   Column               Non-Null Count   Dtype   \n",
            "---  ------               --------------   -----   \n",
            " 0   age                  101766 non-null  category\n",
            " 1   gender               101766 non-null  category\n",
            " 2   race                 101766 non-null  category\n",
            " 3   time_in_hospital     101766 non-null  int64   \n",
            " 4   num_lab_procedures   101766 non-null  int64   \n",
            " 5   num_procedures       101766 non-null  int64   \n",
            " 6   num_medications      101766 non-null  int64   \n",
            " 7   number_diagnoses     101766 non-null  int64   \n",
            " 8   max_glu_serum        101766 non-null  category\n",
            " 9   A1Cresult            101766 non-null  category\n",
            " 10  insulin              101766 non-null  category\n",
            " 11  had_emergency        101766 non-null  category\n",
            " 12  had_inpatient_days   101766 non-null  category\n",
            " 13  had_outpatient_days  101766 non-null  category\n",
            " 14  readmit_30_days      101766 non-null  int64   \n",
            "dtypes: category(9), int64(6)\n",
            "memory usage: 5.5 MB\n"
          ]
        }
      ],
      "source": [
        "selection = [\n",
        "    \"age\",\n",
        "    \"gender\",\n",
        "    \"race\",\n",
        "    \"time_in_hospital\",\n",
        "    \"num_lab_procedures\",\n",
        "    \"num_procedures\",\n",
        "    \"num_medications\",\n",
        "    \"number_diagnoses\",\n",
        "    \"max_glu_serum\",\n",
        "    \"A1Cresult\",\n",
        "    \"insulin\",\n",
        "    \"had_emergency\",\n",
        "    \"had_inpatient_days\",\n",
        "    \"had_outpatient_days\"]\n",
        "\n",
        "categorical_features = [\n",
        "    \"had_emergency\",\n",
        "    \"had_inpatient_days\",\n",
        "    \"had_outpatient_days\",\n",
        "    \"age\",\n",
        "    \"gender\",\n",
        "    \"race\",\n",
        "    \"max_glu_serum\",\n",
        "    \"A1Cresult\",\n",
        "    \"insulin\"]\n",
        "\n",
        "numerical_features = list(set(selection) - set(categorical_features))\n",
        "\n",
        "df_diabetes = dataset.data[selection].copy(deep=True)\n",
        "\n",
        "label = 'readmit_30_days'\n",
        "\n",
        "df_diabetes[label] = dataset.target\n",
        "\n",
        "for categorical_feature in categorical_features:\n",
        "    df_diabetes[categorical_feature] = df_diabetes[categorical_feature].astype('category')\n",
        "df_diabetes.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96bf1661",
      "metadata": {
        "id": "96bf1661"
      },
      "source": [
        "### Question1 : Count the number of positive and negative label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cef2b01",
      "metadata": {
        "id": "0cef2b01"
      },
      "source": [
        "### Question2: Display the distribution of the numerical features and compute their correlation with the target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98cf6382",
      "metadata": {
        "id": "98cf6382"
      },
      "source": [
        "### Question3: Display histogram of categorical distribution by label for each categorical features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4796cf6b",
      "metadata": {
        "id": "4796cf6b"
      },
      "source": [
        "### Question 4: Compute base rate metrics for a sensitive binary attribute (gender, race etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bebb7bc",
      "metadata": {
        "id": "0bebb7bc"
      },
      "source": [
        "## Part 2: MEPS dataset analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25441d6",
      "metadata": {
        "id": "f25441d6"
      },
      "source": [
        "###  Download and simplify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "86d9cb79",
      "metadata": {
        "id": "86d9cb79"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', append=True, category=UserWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a2619054",
      "metadata": {
        "id": "a2619054"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "from aif360.datasets import MEPSDataset19\n",
        "from aif360.datasets import MEPSDataset20\n",
        "from aif360.datasets import MEPSDataset21\n",
        "\n",
        "MEPSDataset19_data = MEPSDataset19()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "182ef40d",
      "metadata": {
        "id": "182ef40d",
        "outputId": "1b55d504-2c21-4d88-a387-aea66668d910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dataset len 15830, total weight of the dataset 141367240.546316.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "instance_weights = MEPSDataset19_data.instance_weights\n",
        "f\"Dataset len {len(instance_weights)}, total weight of the dataset {instance_weights.sum()}.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef8ced7",
      "metadata": {
        "id": "9ef8ced7"
      },
      "source": [
        "### First overview of the dataset\n",
        "\n",
        "The AIF360 library provides a wrapper around the dataset, making it a bit less intuitive to use (for example, to study/visualize the attributes one by one), but it allows fairness metrics to be computed with a single command line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3b92fd21",
      "metadata": {
        "id": "3b92fd21",
        "outputId": "7f589df0-2478-4ee8-d934-32433648022c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49826823461176517\n"
          ]
        }
      ],
      "source": [
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "metric_orig_panel19_train = BinaryLabelDatasetMetric(\n",
        "        MEPSDataset19_data,\n",
        "        unprivileged_groups=[{'RACE': 0}],\n",
        "        privileged_groups=[{'RACE': 1}])\n",
        "\n",
        "print(metric_orig_panel19_train.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3b6771",
      "metadata": {
        "id": "4a3b6771"
      },
      "source": [
        "However, since the aim of this lab is still to manipulate and analyze the data, we will return to working with the data in the form of a dataframe.\n",
        "\n",
        "Note: To calculate fairness metrics without having to re-implement them for the weighted case (instance weights), you can use the methods implemented in AIF360 here: [Fairness Metrics Implementation](https://aif360.readthedocs.io/en/latest/modules/sklearn.html#module-aif360.sklearn.metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e71c40",
      "metadata": {
        "id": "97e71c40"
      },
      "source": [
        "### Conversion to a DataFrame\n",
        "\n",
        "We have seen that the sum of the weights is significant, nearly 115 million, so we cannot reasonably duplicate each row as many times as its weight.\n",
        "\n",
        "We will store the weighting and take it into account later in our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "69f6cdc8",
      "metadata": {
        "id": "69f6cdc8"
      },
      "outputs": [],
      "source": [
        "def get_df(MepsDataset):\n",
        "    data = MepsDataset.convert_to_dataframe()\n",
        "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
        "    df = data[0]\n",
        "    df['WEIGHT'] = data[1]['instance_weights']\n",
        "    return df\n",
        "\n",
        "df_meps = get_df(MEPSDataset19_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d071f9c",
      "metadata": {
        "id": "5d071f9c",
        "outputId": "b8471239-f230-4471-cccf-e2cd4ea04565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['AGE', 'RACE', 'PCS42', 'MCS42', 'K6SUM42', 'REGION=1', 'REGION=2',\n",
              "       'REGION=3', 'REGION=4', 'SEX=1',\n",
              "       ...\n",
              "       'POVCAT=1', 'POVCAT=2', 'POVCAT=3', 'POVCAT=4', 'POVCAT=5', 'INSCOV=1',\n",
              "       'INSCOV=2', 'INSCOV=3', 'UTILIZATION', 'WEIGHT'],\n",
              "      dtype='object', length=140)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_meps.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "00c10c1d",
      "metadata": {
        "id": "00c10c1d",
        "outputId": "213dcf64-1e92-41b9-85aa-5cdc83c2f426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_rate_truth': np.float64(0.8283006948831333),\n",
              " 'statistical_parity_difference': np.float64(0.13008294988278912),\n",
              " 'disparate_impact_ratio': 1.1746792888264614}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "get_metrics(\n",
        "   y_true=df_meps.UTILIZATION, # list or np.array of truth values\n",
        "   y_pred=None,  # list or np.array of predictions\n",
        "   prot_attr=df_meps.RACE, # list or np.array of protected/sensitive attribute values\n",
        "   priv_group=1, # value taken by the privileged group\n",
        "   pos_label=0, # value taken by the positive truth/prediction\n",
        "   sample_weight=None # list or np.array of weights value\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "241cd6e8",
      "metadata": {
        "id": "241cd6e8",
        "outputId": "039ccee1-2c8f-4101-f48b-54d8d4d8525d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_rate_truth': np.float64(0.7849286063696154),\n",
              " 'statistical_parity_difference': np.float64(0.1350744772647814),\n",
              " 'disparate_impact_ratio': 1.1848351529675123}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "get_metrics(\n",
        "    y_true=df_meps.UTILIZATION, # list or np.array of truth values\n",
        "    y_pred=None,  # list or np.array of predictions\n",
        "    prot_attr=df_meps.RACE, # list or np.array of protected/sensitive attribute values\n",
        "    priv_group=1, # value taken by the privileged group\n",
        "    pos_label=0, # value taken by the positive truth/prediction\n",
        "    sample_weight=df_meps.WEIGHT # list or np.array of weights value\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf79e4e",
      "metadata": {
        "id": "3cf79e4e"
      },
      "source": [
        "### Question 5.1 - Faire l'étude descriptive univarié de la couleur de peau ('RACE') (effectif, fréquence, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3483cba8",
      "metadata": {
        "id": "3483cba8"
      },
      "source": [
        "### Question 5.2 - Faire des graphiques décrivant la couleur de peau  (diagramme en secteur, diagramme en barres)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f4de494",
      "metadata": {
        "id": "3f4de494"
      },
      "source": [
        "### Question 5.3 - Faire l'analyse bivariée entre la couleur de peau et les autres variables explicatives quantitatives (boite à moustaches des variables par genre, densité/histogramme par genre, rapport de corrélation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36a0da28",
      "metadata": {
        "id": "36a0da28"
      },
      "source": [
        "### Question 5.4 - Faire l'analyse bivariée entre la couleur de peau et d'autres variables explicatives qualitative (table de contingence, diagramme en barre selon les profils lignes et selon les profils colonnes, diagramme en mosaique)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc482ff6",
      "metadata": {
        "id": "bc482ff6"
      },
      "source": [
        "### Question 5.5 - Faire l'analyse bivariée entre la couleur de peau et la colonne 'UTILIZATION'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8318d87f",
      "metadata": {
        "id": "8318d87f"
      },
      "source": [
        "### Question 6 - Faire la même analyse que la question 5 avec une autre colonne sensible (sexe, âge, etc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktGfQX9yWV8y"
      },
      "id": "ktGfQX9yWV8y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TD_bias_mitigation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}