{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alheliou/Bias_mitigation/blob/main/TD_model_audit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bba3c09",
      "metadata": {
        "id": "5bba3c09"
      },
      "source": [
        "In this TD the aim is to analyse the decision made by a model (logistic regression) and study the impact of in-processing mitigation.\n",
        "You will use different methods to audit/explain the model:\n",
        "- feature importances with LIME\n",
        "- black box auditing that consider the features by couple\n",
        "- counter factual examples with dice-ml\n",
        "- shapkit\n",
        "\n",
        "You will use different in-processing mitigation approaches\n",
        "\n",
        "Then, you will use the Prejudice Remover appraoch (based on a logistic regression) and analyse how the metrics are improved by this mitigation\n",
        "\n",
        "## Installation of the environnement\n",
        "\n",
        "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
        "\n",
        "### Colab Settings\n",
        "  The next two cells of code are too execute only once per colab environment\n",
        "\n",
        "\n",
        "#### 1. Python env creation\n",
        "\n",
        "        ```\n",
        "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "\n",
        "#### 2. Download MEPS dataset (for part2) it can take several minutes\n",
        "\n",
        "        ```\n",
        "        ! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
        "        ! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ```\n",
        "\n",
        "  \n",
        "### Local Settings ( you don't need to redo this, just put the second notebook in the same folder as the first)\n",
        "\n",
        "#### 1. Uv installation\n",
        "\n",
        "\n",
        "        https://docs.astral.sh/uv/getting-started/installation/\n",
        "\n",
        "\n",
        "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
        "\n",
        "        Python version 3.12 installation (highly recommended)\n",
        "        `uv python install 3.12`\n",
        "\n",
        "#### 2. R installation (needed for data download/pre-processing only of Part 2)\n",
        "\n",
        "        In the command `Rscript` says 'command not found'\n",
        "\n",
        "        `sudo apt install r-base-core`\n",
        "\n",
        "#### 3. Python env creation\n",
        "\n",
        "        ```\n",
        "        mkdir TD_bias_mitigation\n",
        "        cd TD_bias_mitigation\n",
        "        uv python pin 3.12\n",
        "        uv init\n",
        "        uv pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "\n",
        "#### 4. Download MEPS dataset it can take several minutes\n",
        "\n",
        "        ```\n",
        "        cd TD_bias_mitigation/.venv/lib/python3.12/site-packages/aif360/data/raw/meps/\n",
        "        Rscript generate_data.R\n",
        "        ```\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e9fa97",
      "metadata": {
        "id": "a0e9fa97"
      },
      "outputs": [],
      "source": [
        "# To execute only in Colab\n",
        "! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
        "! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9010714",
      "metadata": {
        "id": "c9010714"
      },
      "outputs": [],
      "source": [
        "# Code to compute fairness metrics using aif360\n",
        "\n",
        "from aif360.sklearn.metrics import *\n",
        "from sklearn.metrics import  balanced_accuracy_score\n",
        "\n",
        "\n",
        "# This method takes lists\n",
        "def get_metrics(\n",
        "    y_true, # list or np.array of truth values\n",
        "    y_pred=None,  # list or np.array of predictions\n",
        "    prot_attr=None, # list or np.array of protected/sensitive attribute values\n",
        "    priv_group=1, # value taken by the privileged group\n",
        "    pos_label=1, # value taken by the positive truth/prediction\n",
        "    sample_weight=None # list or np.array of weights value,\n",
        "):\n",
        "    group_metrics = {}\n",
        "    group_metrics[\"base_rate_truth\"] = base_rate(\n",
        "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    if not y_pred is None:\n",
        "        group_metrics[\"base_rate_preds\"] = base_rate(\n",
        "        y_true=y_pred, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        if len(set(y_pred))>1:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
        "                y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "            )\n",
        "        else:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] =None\n",
        "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"balanced_accuracy_score\"] = balanced_accuracy_score(\n",
        "        y_true=y_true, y_pred=y_pred, sample_weight=sample_weight\n",
        "        )\n",
        "    return group_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e3f4c72",
      "metadata": {
        "id": "0e3f4c72"
      },
      "source": [
        "## Import and load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10994ae4",
      "metadata": {
        "id": "10994ae4"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.simplefilter(action=\"ignore\", append=True, category=UserWarning)\n",
        "# Datasets\n",
        "from aif360.datasets import MEPSDataset19\n",
        "\n",
        "# Fairness metrics\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "MEPSDataset19_data = MEPSDataset19()\n",
        "(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test) = (\n",
        "    MEPSDataset19().split([0.5, 0.8], shuffle=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc166e3",
      "metadata": {
        "id": "ffc166e3"
      },
      "source": [
        "### Observe fairness metrics in datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1830f884",
      "metadata": {
        "id": "1830f884",
        "outputId": "1d724010-e940-4628-deaa-83631cb619d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base_rate_truth: train 0.7843113407893261, val 0.7808653966877895, test 0.7925663329522626\n",
            "statistical_parity_difference: train 0.13647991784360136, val 0.1432319693902525, test 0.11921166597551425\n",
            "disparate_impact_ratio: train 1.1869289902308444, val 1.1980019769846824, test 1.160288017038563\n"
          ]
        }
      ],
      "source": [
        "train_metrics = get_metrics(\n",
        "    y_true=dataset_orig_panel19_train.labels[:,0],\n",
        "    y_pred=None,\n",
        "    priv_group=1,\n",
        "    pos_label=0,\n",
        "    prot_attr=dataset_orig_panel19_train.protected_attributes[:,0],\n",
        "    sample_weight=dataset_orig_panel19_train.instance_weights)\n",
        "val_metrics = get_metrics(\n",
        "    y_true=dataset_orig_panel19_val.labels[:,0],\n",
        "    y_pred=None,\n",
        "    priv_group=1,\n",
        "    pos_label=0,\n",
        "    prot_attr=dataset_orig_panel19_val.protected_attributes[:,0],\n",
        "    sample_weight=dataset_orig_panel19_val.instance_weights)\n",
        "test_metrics = get_metrics(\n",
        "    y_true=dataset_orig_panel19_test.labels[:,0],\n",
        "    y_pred=None,\n",
        "    priv_group=1,\n",
        "    pos_label=0,\n",
        "    prot_attr=dataset_orig_panel19_test.protected_attributes[:,0],\n",
        "    sample_weight=dataset_orig_panel19_test.instance_weights)\n",
        "\n",
        "for k, v in train_metrics.items():\n",
        "    print(f\"{k}: train {v}, val {val_metrics[k]}, test {test_metrics[k]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5734c0c5",
      "metadata": {
        "id": "5734c0c5"
      },
      "source": [
        "## Part 1 model auditing\n",
        "\n",
        "### Question 1 using LIME\n",
        "#### Question 1.1 - Learn a Logistic Regression to predict UTILIZATION, evaluate the fairness of the predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "602467ed",
      "metadata": {
        "id": "602467ed"
      },
      "source": [
        "#### Question 1.2 (optional) – Observe the impact of the threshold on the performance of logistic regression (balanced accuracy and disparate impact)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e15ccc",
      "metadata": {
        "id": "e9e15ccc"
      },
      "source": [
        "\n",
        "#### Question 1.3: Train a LimeEncoder (name the object `lime_data`) on the AIF360 training dataset, then use this LimeEncoder to transform both the training and valid datasets into `s_train` and `s_valid`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6992aad0",
      "metadata": {
        "id": "6992aad0"
      },
      "source": [
        "#### Question 1.4 use LimeTabularExplainer to explain the decision made on several instances of the valid dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "647ecb81",
      "metadata": {
        "id": "647ecb81"
      },
      "outputs": [],
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "explainer = LimeTabularExplainer(\n",
        "        s_train,\n",
        "        class_names=lime_data.s_class_names,\n",
        "        feature_names=lime_data.s_feature_names,\n",
        "        categorical_features=lime_data.s_categorical_features,\n",
        "        categorical_names=lime_data.s_categorical_names,\n",
        "        kernel_width=3, verbose=False, discretize_continuous=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8bb9a1a",
      "metadata": {
        "id": "e8bb9a1a"
      },
      "source": [
        "### Question 2: Using BlackBoxAuditing\n",
        "\n",
        "Be careful: this time, we are interested in indirect influences, as this method considers features in pairs.\n",
        "\n",
        "Also, transforming categorical attributes using \"one hot encoding\" is not a good approach here because these columns will, by design, be highly correlated with each other.\n",
        "\n",
        "Instead, we will use ordinal encoding, and only use sklearn classifiers that are compatible with categorical features (HistGradientBoostingClassifier).\n",
        "\n",
        "First, you should convert the AIF dataset to a dataframe and group together the columns that were already one-hot encoded , then apply ordinal encoding to the categorical columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f28e39",
      "metadata": {
        "id": "27f28e39"
      },
      "outputs": [],
      "source": [
        "from BlackBoxAuditing.data import load_from_file\n",
        "from BlackBoxAuditing.model_factories.AbstractModelFactory import AbstractModelFactory\n",
        "from BlackBoxAuditing.model_factories.AbstractModelVisitor import AbstractModelVisitor\n",
        "\n",
        "import BlackBoxAuditing as BBA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90032b61",
      "metadata": {
        "id": "90032b61"
      },
      "source": [
        "#### Question 2.1: Preprocess the data\n",
        "\n",
        "To allow you to spend more time working with explanations, we provide the code to properly format the dataframe; you can move on to section 2.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1116dde6",
      "metadata": {
        "id": "1116dde6",
        "outputId": "0598bd9f-a5bd-4ad4-cd09-4867483d8492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['REGION', 'SEX', 'MARRY', 'FTSTU', 'ACTDTY', 'HONRDC', 'RTHLTH', 'MNHLTH', 'HIBPDX', 'CHDDX', 'ANGIDX', 'MIDX', 'OHRTDX', 'STRKDX', 'EMPHDX', 'CHBRON', 'CHOLDX', 'CANCERDX', 'DIABDX', 'JTPAIN', 'ARTHDX', 'ARTHTYPE', 'ASTHDX', 'ADHDADDX', 'PREGNT', 'WLKLIM', 'ACTLIM', 'SOCLIM', 'COGLIM', 'DFHEAR42', 'DFSEE42', 'ADSMOK42', 'PHQ242', 'EMPST', 'POVCAT', 'INSCOV'])\n"
          ]
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "def get_df(MepsDataset, encoders=None):\n",
        "    data = MepsDataset.convert_to_dataframe()\n",
        "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
        "    df = data[0]\n",
        "    df[\"WEIGHT\"] = data[1][\"instance_weights\"]\n",
        "    # Get categorical column from one hot encoding (specitic to MEPSdataset)\n",
        "    # Here we create a dictionnary that links each categorical column name\n",
        "    # to the list of corresponding one hot encoded columns\n",
        "    categorical_columns_dic = {}\n",
        "    for col in df.columns:\n",
        "        col_split = col.split(\"=\")\n",
        "        if len(col_split) > 1:\n",
        "            cat_col = col_split[0]\n",
        "            if not (cat_col in categorical_columns_dic.keys()):\n",
        "                categorical_columns_dic[cat_col] = []\n",
        "            categorical_columns_dic[cat_col].append(col)\n",
        "    categorical_features = categorical_columns_dic.keys()\n",
        "    print(categorical_features)\n",
        "\n",
        "    def categorical_transform(df, onehotencoded, cat_col):\n",
        "        if len(onehotencoded) > 1:\n",
        "            return df[onehotencoded].apply(\n",
        "                lambda x: onehotencoded[np.argmax(x)][len(cat_col) + 1 :], axis=1\n",
        "            )\n",
        "        else:\n",
        "            return df[onehotencoded]\n",
        "\n",
        "\n",
        "    # Reverse the categorical one hot encoded\n",
        "    for cat_col, onehotencoded in categorical_columns_dic.items():\n",
        "        df[cat_col] = categorical_transform(df, onehotencoded, cat_col)\n",
        "        df.drop(columns=onehotencoded, inplace=True)\n",
        "\n",
        "    if encoders is None:\n",
        "        encoders= {}\n",
        "        #encoders = {cat_col:preprocessing.LabelEncoder() for cat_col in categorical_features}\n",
        "\n",
        "    for cat_col in categorical_features:\n",
        "        if not (cat_col in encoders.keys()):\n",
        "            encoders[cat_col] = preprocessing.LabelEncoder().fit(df[cat_col])\n",
        "\n",
        "        df[cat_col] = encoders[cat_col].transform(df[cat_col])\n",
        "    return df, encoders\n",
        "\n",
        "\n",
        "df, encoders = get_df(MEPSDataset19_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2982a8c0",
      "metadata": {
        "id": "2982a8c0"
      },
      "source": [
        "#### Question 2.2  transform train, val and test dataset to dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "444212f1",
      "metadata": {
        "id": "444212f1"
      },
      "source": [
        "#### Question 2.3: Learn a HistGradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2b312ca",
      "metadata": {
        "id": "f2b312ca"
      },
      "source": [
        "#### Question 2.4 Use the BlackBoxAuditing library to \"audit\" the model by analyzing the indirect influences of age (the computation takes time, but feel free to try other attributes as well)\n",
        "\n",
        "The code is provided again; you just need to adapt it to your own notation.\n",
        "\n",
        "Here is the documentation for the library used:  \n",
        "https://github.com/algofairness/BlackBoxAuditing/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29bfb0e9",
      "metadata": {
        "id": "29bfb0e9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save your data and model (named clf here) on disk\n",
        "\n",
        "data_val = df_X_val.copy(deep=True)\n",
        "data_val[\"Y\"] = df_y_val\n",
        "\n",
        "data_val.to_csv(\"data_val.csv\",\n",
        "          index=False)\n",
        "\n",
        "data_train = df_X_train.copy(deep=True)\n",
        "data_train[\"Y\"] = df_y_train\n",
        "\n",
        "data_train.to_csv(\"data_train.csv\",\n",
        "          index=False)\n",
        "\n",
        "with open( 'TD2_clf.pickle', 'wb' ) as f:\n",
        "    pickle.dump(clf, f )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f33c84",
      "metadata": {
        "id": "18f33c84"
      },
      "outputs": [],
      "source": [
        "from BlackBoxAuditing.data import load_from_file\n",
        "from BlackBoxAuditing.model_factories.AbstractModelFactory import AbstractModelFactory\n",
        "from BlackBoxAuditing.model_factories.AbstractModelVisitor import AbstractModelVisitor\n",
        "\n",
        "import BlackBoxAuditing as BBA\n",
        "\n",
        "\n",
        "(_, train_BBA, _, _, _, _) = load_from_file(\"data_train.csv\",\n",
        "                      correct_types = [int if col_type==\"int\" else float for col_type in  data_train.dtypes],\n",
        "                                response_header = 'Y',\n",
        "                               train_percentage = 1.0)\n",
        "(headers, _, val_BBA, response_header, features_to_ignore, correct_types) = load_from_file(\"data_val.csv\",\n",
        "                      correct_types = [int if col_type==\"int\" else float for col_type in  data_val.dtypes],\n",
        "                                response_header = 'Y',\n",
        "                               train_percentage = 0.0)\n",
        "BBA_data = (headers, train_BBA, val_BBA, response_header, features_to_ignore, correct_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faae6ba",
      "metadata": {
        "id": "9faae6ba"
      },
      "outputs": [],
      "source": [
        "class HirePredictorBuilder(AbstractModelFactory):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        AbstractModelFactory.__init__(self, *args, **kwargs)\n",
        "        self.verbose_factory_name = \"HirePredictor\"\n",
        "    def build(self, train_set):\n",
        "        return HirePredictor()\n",
        "\n",
        "class HirePredictor(AbstractModelVisitor):\n",
        "    def __init__(self):\n",
        "        with open( 'TD2_clf.pickle', 'rb' ) as f:\n",
        "            self.clf = pickle.load(f)\n",
        "\n",
        "    def test(self, val_set, test_name=\"\"):\n",
        "        return [[v[-1], self.clf.predict(np.expand_dims(np.array(v[:-1]), axis = 0))] for v in val_set]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf55c79",
      "metadata": {
        "id": "5bf55c79"
      },
      "outputs": [],
      "source": [
        "features_to_audit = [\n",
        "    \"AGE\",\n",
        "    \"SEX\",\n",
        "    \"RACE\",\n",
        "    \"REGION\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a503a44",
      "metadata": {
        "id": "0a503a44"
      },
      "outputs": [],
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "auditor = BBA.Auditor()\n",
        "auditor.ModelFactory = HirePredictorBuilder\n",
        "auditor(BBA_data, output_dir = \"audit-output\", features_to_audit=features_to_audit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e76a538",
      "metadata": {
        "id": "9e76a538"
      },
      "source": [
        "### Question 3: Generer des exemples contrefactuels en utilisant dice-ml\n",
        "\n",
        "Voici la documentation de la librairie utilisée\n",
        "https://github.com/interpretml/DiCE?tab=readme-ov-file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec8a881",
      "metadata": {
        "id": "8ec8a881"
      },
      "outputs": [],
      "source": [
        "import dice_ml\n",
        "from dice_ml.utils import helpers\n",
        "# provide the trained ML model to DiCE's model object\n",
        "# use the HistGradientBoostingClassifier from the BlackBoxAuditiing\n",
        "backend = 'sklearn'\n",
        "m = dice_ml.Model(model=clf, backend=backend)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c886896",
      "metadata": {
        "id": "9c886896"
      },
      "source": [
        "#### Question 3.1 : Create a list with all numerical features\n",
        "\n",
        "This question uses the variables created in the provided answer of question 2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cd66001",
      "metadata": {
        "id": "0cd66001"
      },
      "source": [
        "#### Question 3.2 ceate a dice_ml Data with the dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "505856ad",
      "metadata": {
        "id": "505856ad"
      },
      "source": [
        "#### Question 3.3  use dice to create counterfactual example using the 'random' method"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8361e45",
      "metadata": {
        "id": "e8361e45"
      },
      "source": [
        "## Part 2 In-processing mitigation\n",
        "###  Question1 : Learn a Standard Scaler on the training dataset features, its output will be used as input of the model learned"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36951dc9",
      "metadata": {
        "id": "36951dc9"
      },
      "source": [
        "### Question2: Create a method to learn a Prejudice Remover on the train dataset and retrieve the model learned\n",
        "Execute the method with the parameter eta arbitrarily set at 25.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04cd1936",
      "metadata": {
        "id": "04cd1936"
      },
      "outputs": [],
      "source": [
        "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
        "\n",
        "def train_pr_model(train_dataset, eta=25.0):\n",
        "    model = PrejudiceRemover(sensitive_attr='RACE', eta=eta)\n",
        "    pr_orig_panel19 = model.fit(train_dataset)\n",
        "    return pr_orig_panel19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a50bd9",
      "metadata": {
        "id": "43a50bd9"
      },
      "source": [
        "Le score du Prejudice Remover donne un sortie pour chaque instance une seule valeur, c'est un seuil, arbritrairement fixé à 0.5 par défault, qui permet à partir de ce score de décider la prédiction 1 ou 0.\n",
        "Si le score est supérieur au seuil la prédiction est 1, sinon c'est 0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "216e48a0",
      "metadata": {
        "id": "216e48a0"
      },
      "source": [
        "### Question3: Validating: Choose the best parameters\n",
        "\n",
        "Here there are two parameters :\n",
        "- eta: fairness penalty parameter of the PR model\n",
        "- thershold: the threshold of the binary classification\n",
        "\n",
        "The threshold is used to obtains predictions from the model output.\n",
        "The eta is used during the training\n",
        "\n",
        "=> Create a method that will loop over 50 threshold ]0:0.5( and 5 values of ETA [1.0: 100.0], and outputs the metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92f6ea4",
      "metadata": {
        "id": "a92f6ea4"
      },
      "source": [
        "### Question4 : Make plot to choose the best set of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e68f9b7",
      "metadata": {
        "id": "2e68f9b7"
      },
      "source": [
        "### Question 5: Evaluate : compute the metrics on the test dataset using the model learnt with the selected parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201c8b22",
      "metadata": {
        "id": "201c8b22"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TD_bias_mitigation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}