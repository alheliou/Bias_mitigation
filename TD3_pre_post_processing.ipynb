{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alheliou/Bias_mitigation/blob/main/TD3_pre_post_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRe6S30b9Ng7"
      },
      "source": [
        "# TD 3: Mitigation des biais avec des méthodes de pré-processing et de post-processing\n",
        "\n",
        "## Objectives:\n",
        "\n",
        "    1. Use pre-processing approaches, see if they perform well on the use case\n",
        "\n",
        "    2. Use post-processing approaches, see if they perform well on the use case\n",
        "\n",
        "    3. Try to combine pre-processing with in-processing and/or with post-processing.\n",
        "\n",
        "\n",
        "## Installation of the environnement\n",
        "\n",
        "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
        "\n",
        "### Colab Settings\n",
        "  The next two cells of code are too execute only once per colab environment\n",
        "\n",
        "\n",
        "#### 1. Python env creation\n",
        "\n",
        "        ```\n",
        "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "\n",
        "#### 2. Download MEPS dataset it can take several minutes\n",
        "\n",
        "        ```\n",
        "        ! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
        "        ! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ```\n",
        "\n",
        "  \n",
        "### Local Settings\n",
        "\n",
        "#### 1. Uv installation\n",
        "\n",
        "\n",
        "        https://docs.astral.sh/uv/getting-started/installation/\n",
        "\n",
        "\n",
        "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
        "\n",
        "        Python version 3.12 installation (highly recommended)\n",
        "        `uv python install 3.12`\n",
        "\n",
        "#### 2. R installation (needed for data download/pre-processing only of Part 2)\n",
        "\n",
        "        In the command `Rscript` says 'command not found'\n",
        "\n",
        "        `sudo apt install r-base-core`\n",
        "\n",
        "#### 3. Python env creation\n",
        "\n",
        "        ```\n",
        "        mkdir TD_bias_mitigation\n",
        "        cd TD_bias_mitigation\n",
        "        uv python pin 3.12\n",
        "        uv init\n",
        "        uv pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "\n",
        "#### 4. Download MEPS dataset it can take several minutes\n",
        "\n",
        "        ```\n",
        "        cd TD_bias_mitigation/.venv/lib/python3.12/site-packages/aif360/data/raw/meps/\n",
        "        Rscript generate_data.R\n",
        "        ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9ITNS89NhA"
      },
      "source": [
        "## 1.Manipulate the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88mMZIic9NhB"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.simplefilter(action=\"ignore\", append=True, category=UserWarning)\n",
        "# Datasets\n",
        "from aif360.datasets import MEPSDataset19\n",
        "from aif360.explainers import MetricTextExplainer\n",
        "\n",
        "# Fairness metrics\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "\n",
        "MEPSDataset19_data = MEPSDataset19()\n",
        "(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test) = (\n",
        "    MEPSDataset19().split([0.5, 0.8], shuffle=True)\n",
        ") # 50% train, 30% val, 20% test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYbdfIPs9NhE",
        "outputId": "3e2b03b4-b532-4aed-8379-ebf6b9288a0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7915, 4749, 3166)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_orig_panel19_train.instance_weights), len(\n",
        "    dataset_orig_panel19_val.instance_weights\n",
        "), len(dataset_orig_panel19_test.instance_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki3vPRSGQVvj",
        "outputId": "0b8f5a00-e895-4ed6-8c64-dee1e746e03b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([21854.981705, 18169.604822, 17191.832515, ...,  3896.116219,\n",
              "        4883.851005,  6630.588948], shape=(15830,))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "instance_weights = MEPSDataset19_data.instance_weights\n",
        "instance_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYjdRUOHQVvj",
        "outputId": "c674d24b-7c60-4291-b300-3418d190239f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Taille du dataset 15830, poids total du dataset 141367240.546316.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f\"Taille du dataset {len(instance_weights)}, poids total du dataset {instance_weights.sum()}.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3M0uNDzQVvj"
      },
      "source": [
        "### Conversion to a DataFrame\n",
        "\n",
        "We have seen that the sum of the weights is significant, nearly 115 million, so we cannot reasonably duplicate each row as many times as its weight.\n",
        "\n",
        "We will store the weighting and take it into account later in our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N2PO_PaQVvj"
      },
      "outputs": [],
      "source": [
        "def get_df(MepsDataset):\n",
        "    data = MepsDataset.convert_to_dataframe()\n",
        "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
        "    df = data[0]\n",
        "    df[\"WEIGHT\"] = data[1][\"instance_weights\"]\n",
        "    return df\n",
        "\n",
        "\n",
        "df = get_df(MEPSDataset19_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY0FXVLdQVvj"
      },
      "source": [
        "Method that prints the fairness metrics of a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah6tnyOt9NhF"
      },
      "outputs": [],
      "source": [
        "# Code to compute fairness metrics using aif360\n",
        "\n",
        "from aif360.sklearn.metrics import *\n",
        "from sklearn.metrics import  balanced_accuracy_score\n",
        "\n",
        "\n",
        "# This method takes lists\n",
        "def get_metrics(\n",
        "    y_true, # list or np.array of truth values\n",
        "    y_pred=None,  # list or np.array of predictions\n",
        "    prot_attr=None, # list or np.array of protected/sensitive attribute values\n",
        "    priv_group=1, # value taken by the privileged group\n",
        "    pos_label=1, # value taken by the positive truth/prediction\n",
        "    sample_weight=None # list or np.array of weights value,\n",
        "):\n",
        "    group_metrics = {}\n",
        "    group_metrics[\"base_rate_truth\"] = base_rate(\n",
        "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    if not y_pred is None:\n",
        "        group_metrics[\"base_rate_preds\"] = base_rate(\n",
        "        y_true=y_pred, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        if len(set(y_pred))>1:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
        "                y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "            )\n",
        "        else:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] =None\n",
        "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"balanced_accuracy_score\"] = balanced_accuracy_score(\n",
        "        y_true=y_true, y_pred=y_pred, sample_weight=sample_weight\n",
        "        )\n",
        "    return group_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqoGHHAYQVvk",
        "outputId": "e3533543-8747-45a1-cfa3-3b348b1ec806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'base_rate_truth': np.float64(0.7849286063696154),\n",
              " 'statistical_parity_difference': np.float64(0.1350744772647814),\n",
              " 'disparate_impact_ratio': 1.1848351529675123}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_metrics(\n",
        "        y_true= df.UTILIZATION,\n",
        "        y_pred= None,\n",
        "        prot_attr= df.RACE,\n",
        "        priv_group= 1,\n",
        "        pos_label= 0,\n",
        "        sample_weight= df.WEIGHT,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Zbw-U4mTKf"
      },
      "source": [
        "## Part 2. Apply AIF360 pre-processing methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ann10-KBQVvk",
        "outputId": "3a6dd93c-c738-4a6a-8779-86d54c646e5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('RACE', [{'RACE': np.float64(0.0)}], [{'RACE': np.float64(1.0)}])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sens_ind = 0\n",
        "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
        "unprivileged_groups = [\n",
        "    {sens_attr: v}\n",
        "    for v in dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]\n",
        "]\n",
        "privileged_groups = [\n",
        "    {sens_attr: v}\n",
        "    for v in dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]\n",
        "]\n",
        "sens_attr, unprivileged_groups, privileged_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUpk2YewQVvl"
      },
      "source": [
        "### 2.1.1 Quesiton: Train a logistic regression to predict the 'UTILIZATION'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG9N7WVBQVvl"
      },
      "source": [
        "### 2.1.2 Question : compute the accuracy and its balanced accuracy (balanced per class), with and without the instance weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJT9bgtnQVvl"
      },
      "source": [
        "### 2.2 Question: Bias metrics\n",
        "\n",
        "Compute the metrics on the validation dataset, does the model amplify the bias ?\n",
        "\n",
        "You can compare the metrics using the truth as the prediction, or random predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYQBU04oQVvl"
      },
      "source": [
        "### 2.2 Reweighing\n",
        "#### 2.2.1. Question : Find in the [API](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.Reweighing.html) which objects/functions should be used for reweighting and apply them to the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmAXlUZTQVvl"
      },
      "source": [
        "#### 2.2.2. Question: Train a logistic regression of the reweighted training dataset. Then compute the accuracy, balanced accuracy and fairness metrics on the validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWYGdZwQVvl"
      },
      "source": [
        "As seens in the lesson, Reweighting change only the instance weights, the features and label remain the same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfA2nARRQVvl"
      },
      "source": [
        "### 2.3. Disparate Impact Remover\n",
        "#### 2.3.1. Question : Find in the [API](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.DisparateImpactRemover.html) which objects/functions should be used for disparate impact remover and apply them to the datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djy9t3aVQVvl"
      },
      "source": [
        "#### 2.3.2. Question: Train a logistic regression on the transform dataset without the sensitive attribute and compute the fairness metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqE5p3AUQVvl"
      },
      "source": [
        "### 2.4. Question: Train a Latent Fair Representation [API](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.preprocessing.LFR.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agRyQEe8QVvl"
      },
      "source": [
        "## Part 3 Post processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wQUVYTLQVvl"
      },
      "source": [
        "### 3.1 Post-processing [Reject Option Classification](https://aif360.readthedocs.io/en/latest/modules/generated/aif360.algorithms.postprocessing.RejectOptionClassification.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMbJEvoLQVvm"
      },
      "source": [
        "#### 3.1.1 Reuse the first Logistic Regression learn to find the best threshold that maximises its balanced accuracy on the validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKudILG7QVvm"
      },
      "source": [
        "#### 3.1.2 Use the RejectOptionClassification  on the validation dataset with the logistic regression predictions. To improve the fairness metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elm1CSSFQVvm"
      },
      "source": [
        "#### 3.1.3 Do the same while starting from the Logistic Regression learned on the Reweighted dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgem_A8YQVvm"
      },
      "source": [
        "#### 3.2 Use the Calibrated Equalised Odds  on the validation dataset with the logistic regression predictions. To improve the fairness metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG_D6tCoQVvm"
      },
      "source": [
        "## Part 4: Combine pre-processing and in-processing approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUGEEfMRQVvm"
      },
      "source": [
        "Combine the ReWeighing with the Prejudice Remover (has seen in TD2, 14th of october)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE1rW42iQVvm"
      },
      "source": [
        "## Part Optional : Study the impact of Reweighing on different models\n",
        "\n",
        "Does it impact Decision Tree, why not ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPPnlbJiQVvm"
      },
      "source": [
        "from sklearn import tree\n",
        "DTclf = tree.DecisionTreeClassifier()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "TD_bias_mitigation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}