{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alheliou/Bias_mitigation/blob/main/UPP26/TD1_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZJSs4w9BCK-"
      },
      "source": [
        "# TD 1: Fairness notion examples\n",
        "\n",
        "In this first TD we are going to manipulate some data and see the behaviour of the different fairness metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVTQA5nQoY07"
      },
      "source": [
        "## Installation of the environnement\n",
        "\n",
        "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
        "\n",
        "### Colab Settings ---- for Colab Users ONLY\n",
        "  The next cell of code are to execute only once per colab environment\n",
        "\n",
        "\n",
        "#### Python env creation (Colab only)\n",
        "\n",
        "        ```\n",
        "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "### Local Settings ---- for installation on local computer ONLY\n",
        "\n",
        "#### 1. Uv installation (local only)\n",
        "\n",
        "\n",
        "        https://docs.astral.sh/uv/getting-started/installation/\n",
        "\n",
        "\n",
        "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
        "\n",
        "        Python version 3.12 installation (highly recommended)\n",
        "        `uv python install 3.12`\n",
        "\n",
        "\n",
        "#### 3. Python env creation (local only)\n",
        "\n",
        "        ```\n",
        "        mkdir TD_bias_mitigation\n",
        "        cd TD_bias_mitigation\n",
        "        uv python pin 3.12\n",
        "        uv init\n",
        "        uv venv\n",
        "        uv pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCKXApFuBCLC"
      },
      "source": [
        "\n",
        "## Objectives\n",
        "\n",
        "\n",
        " 1. Study the data, the distribution of each feature and its relation to the target.\n",
        "\n",
        " 2. Highlight some bias present in the data\n",
        "\n",
        " 3. Learn a basic machine learning model using logistic regression\n",
        "\n",
        " 4. Compute the confusion matrix and different fairness metrics\n",
        "\n",
        "## Dataset: Diabetes 130-Hospitals\n",
        "\n",
        "\n",
        "https://fairlearn.org/main/api_reference/generated/fairlearn.datasets.fetch_diabetes_hospital.html\n",
        "\n",
        "Ce dataset contient 101,766 lignes chacunes concernant un patient hospitalisé pour du diabètes sur une durée allant de 1 à 14 jours. Les données ont été récoltées sur 10 ans et 130 hopitaux différents. Chaque donnée possède 25 caractéristiques concernant des informations médicales, mais aussi demographiques, enfin la colonne 'readmitted' indique si le patient a été réadmis, et si oui s'il l'a été dans les 30jours ou après. Cette colonne est binarisée en deux autres 'readmit_30_days' (True si réadmis dans les 30 jours, False sinon) et 'readmitted' ( True si réadmis, False sinon).\n",
        "\n",
        "Nous utiliserons en label/vérité, la colonne 'readmit_30_days'.\n",
        "\n",
        "Nous allons simplifier en ne considérant qu'un sous-ensemble de 14 des caractéristiques fournies:\n",
        "age, gender, race, time_in_hospital, num_lab_procedures, num_procedures, num_medications, number_diagnoses, max_glu_serum, A1Cresult, insulin, had_emergency, had_inpatient_days, had_outpatient_days\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkmJ0fyFoY08"
      },
      "outputs": [],
      "source": [
        "# To execute only in Colab\n",
        "! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdyRKBffoY08"
      },
      "outputs": [],
      "source": [
        "# Code to compute fairness metrics using aif360\n",
        "\n",
        "from aif360.sklearn.metrics import *\n",
        "from sklearn.metrics import  balanced_accuracy_score\n",
        "\n",
        "\n",
        "# This method takes lists\n",
        "def get_metrics(\n",
        "    y_true, # list or np.array of truth values\n",
        "    y_pred=None,  # list or np.array of predictions\n",
        "    prot_attr=None, # list or np.array of protected/sensitive attribute values\n",
        "    priv_group=1, # value taken by the privileged group\n",
        "    pos_label=1, # value taken by the positive truth/prediction\n",
        "    sample_weight=None # list or np.array of weights value,\n",
        "):\n",
        "    group_metrics = {}\n",
        "    group_metrics[\"base_rate_truth\"] = base_rate(\n",
        "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "    )\n",
        "    if not y_pred is None:\n",
        "        group_metrics[\"base_rate_preds\"] = base_rate(\n",
        "        y_true=y_pred, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
        "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        if len(set(y_pred))>1:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
        "                y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "            )\n",
        "        else:\n",
        "            group_metrics[\"conditional_demographic_disparity\"] =None\n",
        "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
        "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
        "        )\n",
        "        group_metrics[\"balanced_accuracy_score\"] = balanced_accuracy_score(\n",
        "        y_true=y_true, y_pred=y_pred, sample_weight=sample_weight\n",
        "        )\n",
        "    return group_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6YE9bSd3qgG"
      },
      "source": [
        "## Download and simplify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbEeXIwwKLqa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import fairlearn\n",
        "np.__version__, fairlearn.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3HDPkgdBCLD"
      },
      "outputs": [],
      "source": [
        "from fairlearn.datasets import fetch_diabetes_hospital\n",
        "dataset = fetch_diabetes_hospital()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS5ap_RGBCLG"
      },
      "outputs": [],
      "source": [
        "selection = [\n",
        "    \"age\",\n",
        "    \"gender\",\n",
        "    \"race\",\n",
        "    \"time_in_hospital\",\n",
        "    \"num_lab_procedures\",\n",
        "    \"num_procedures\",\n",
        "    \"num_medications\",\n",
        "    \"number_diagnoses\",\n",
        "    \"max_glu_serum\",\n",
        "    \"A1Cresult\",\n",
        "    \"insulin\",\n",
        "    \"had_emergency\",\n",
        "    \"had_inpatient_days\",\n",
        "    \"had_outpatient_days\"]\n",
        "df = dataset.data[selection].copy(deep=True)\n",
        "label = 'readmit_30_days'\n",
        "df[label] = dataset.target\n",
        "# We transform boolean into integer, False=>0, True=>1\n",
        "df.had_emergency = df.had_emergency.replace({\"True\":1, \"False\":0})\n",
        "df.had_inpatient_days = df.had_inpatient_days.replace({\"True\":1, \"False\":0})\n",
        "df.had_outpatient_days = df.had_outpatient_days.replace({\"True\":1, \"False\":0})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qySVWo6f7FkU"
      },
      "source": [
        "## Part 1: Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qjpeC-OQFDA"
      },
      "source": [
        "### Question1 : Count the number of positive and negative label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpKxdSr3oY08"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLYrjnOlBCLH"
      },
      "source": [
        "Now we look at the different features.\n",
        "First the numerical features\n",
        "\n",
        "### Question2: Display the distribution of the numerical features and compute their correlation with the target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td0AM-NLaPWp"
      },
      "outputs": [],
      "source": [
        "def Compute_correlation(cola, colb):\n",
        "  return np.corrcoef(df[cola].values, df[colb].values)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk53cAZLoY09"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fwQvgwOBtHe"
      },
      "source": [
        "Then we consider the categorical features.\n",
        "\n",
        "### Question3: Display histogram of categorical distribution by label for each categorical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPkvob6lB82i"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "def Display_categorical_hist(cat_feature, target):\n",
        "  fig = px.histogram(df, x=cat_feature, color=target)\n",
        "  fig.show()\n",
        "\n",
        "def Display_categorical_hist_percent(cat_feature, target):\n",
        "  df_summarized = df.groupby([target,cat_feature]).agg(\"count\").reset_index()\n",
        "  df_summarized[f\"percent of {cat_feature}\"] = df_summarized[[cat_feature,\"time_in_hospital\"]].apply(\n",
        "    lambda x: 100*x[1]/df_summarized[df_summarized[cat_feature]==x[0]][\"time_in_hospital\"].sum(), axis=1\n",
        "  )\n",
        "  df_summarized[label] = df_summarized[label].astype(str)\n",
        "  fig = px.bar(df_summarized, x=f\"{cat_feature}\", y=f\"percent of {cat_feature}\", color=target)\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5MLIC7AoY09"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTiqlSctEbX_"
      },
      "source": [
        "### Question4: What are the bias highlighted by the data analysis ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqsUMfiVoY09"
      },
      "outputs": [],
      "source": [
        "print(\"TO WRITE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVXBYtmeGUQ8"
      },
      "source": [
        "## Part 2: Learn a Decision Tree and study the fairness of its output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGdBpyVHG3pA"
      },
      "source": [
        "### Question5: Utiliser la technique du \"one hot encoding\" pour transformer chaque colonne categorielle à N catégories en N colonnes binaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPr1uws0oY09"
      },
      "outputs": [],
      "source": [
        "print(\"TODO: Create df_X, with numerical features and one hot encoded categorical features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qF0cjzOCIp"
      },
      "source": [
        "### Question6 : Split data into train and test sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8O2FYXIEqCp"
      },
      "outputs": [],
      "source": [
        "print(\"TODO: Create X_train, X_test, y_train, y_test, from df_X and the label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLOBuscUORlg"
      },
      "source": [
        "### Question 7: Train a DecisionTreeClassifier (https://scikit-learn.org/stable/modules/tree.html#classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWsdllKaOTao"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl9tq0RbPLWG"
      },
      "source": [
        "### Question8: Compute the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLBdxD7lIdWL"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w20fbl9aP6GW"
      },
      "source": [
        "### Question 9: Compute base rate metrics for a sensitive binary attribute (gender, race etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNTEAVXPLp5E"
      },
      "outputs": [],
      "source": [
        "print(\"TODO compute diparate impact\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTWzh1OgjuE"
      },
      "source": [
        "### Question 10: Compute model perfomance for a sensitive binary attribute (gender, race etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIv9JeSOgjuE"
      },
      "outputs": [],
      "source": [
        "print(\"TODO compute model performance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibLZX7YagjuH"
      },
      "source": [
        "### Question 11: Compute model calibration according to a sensitive binary attribute (gender, race etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4Z466ZyoY09"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
