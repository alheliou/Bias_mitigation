{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alheliou/Bias_mitigation/blob/main/UPP26/TD4_pre_post.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRe6S30b9Ng7"
      },
      "source": [
        "# TD 4: Mitigation des biais avec des méthodes de pré-processing et de post-processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JfRVXvrAVkM"
      },
      "source": [
        "## Installation of the environnement\n",
        "\n",
        "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
        "\n",
        "### Colab Settings ---- for Colab Users ONLY\n",
        "  The next cell of code are to execute only once per colab environment\n",
        "\n",
        "\n",
        "#### Python env creation (Colab only)\n",
        "\n",
        "        ```\n",
        "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        ```\n",
        "#### 2. Download MEPS dataset (for part2) it can take several minutes (Colab only)\n",
        "\n",
        "        ```\n",
        "        ! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
        "        ! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "        ```\n",
        "\n",
        "### Local Settings ---- for installation on local computer ONLY\n",
        "\n",
        "If you arleady have an env from TD2 or TD3, you can simply reuse it.\n",
        "\n",
        "\n",
        "#### 1. Uv installation (local only, no need to redo if already done)\n",
        "\n",
        "\n",
        "        https://docs.astral.sh/uv/getting-started/installation/\n",
        "\n",
        "\n",
        "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
        "\n",
        "        Python version 3.12 installation (highly recommended)\n",
        "        `uv python install 3.12`\n",
        "\n",
        "#### 2. R installation *NEW* (local only)\n",
        "\n",
        "        In the command `Rscript` says 'command not found'\n",
        "\n",
        "        `sudo apt install r-base-core`\n",
        "\n",
        "#### 3. Python env creation (local only, no need to redo if already done)\n",
        "\n",
        "        ```\n",
        "        mkdir TD_bias_mitigation\n",
        "        cd TD_bias_mitigation\n",
        "        uv python pin 3.12\n",
        "        uv init\n",
        "        uv venv\n",
        "        uv add numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
        "        uv add pandas==2.2.2\n",
        "        ```\n",
        "\n",
        "#### 4. Download MEPS dataset, it can take several minutes *NEW* (local only)\n",
        "\n",
        "        ```\n",
        "        cd TD_bias_mitigation/.venv/lib/python3.12/site-packages/aif360/data/raw/meps/\n",
        "        Rscript generate_data.R\n",
        "        ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RovVT0ZAVkM"
      },
      "outputs": [],
      "source": [
        "# To execute only in Colab\n",
        "! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To execute only in Colab\n",
        "! Rscript /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/generate_data.R\n",
        "! mv h181.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/\n",
        "! mv h192.csv /usr/local/lib/python3.12/dist-packages/aif360/data/raw/meps/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9ITNS89NhA"
      },
      "source": [
        "## 1.Manipulate the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88mMZIic9NhB"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.simplefilter(action=\"ignore\", append=True, category=UserWarning)\n",
        "# Datasets\n",
        "from aif360.datasets import MEPSDataset19\n",
        "from aif360.explainers import MetricTextExplainer\n",
        "\n",
        "# Fairness metrics\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "\n",
        "\n",
        "MEPSDataset19_data = MEPSDataset19()\n",
        "(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test) = (\n",
        "    MEPSDataset19().split([0.5, 0.8], shuffle=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYbdfIPs9NhE"
      },
      "outputs": [],
      "source": [
        "len(dataset_orig_panel19_train.instance_weights), len(\n",
        "    dataset_orig_panel19_val.instance_weights\n",
        "), len(dataset_orig_panel19_test.instance_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t93y95AHAVkN"
      },
      "outputs": [],
      "source": [
        "instance_weights = MEPSDataset19_data.instance_weights\n",
        "instance_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABeNqPXrAVkN"
      },
      "outputs": [],
      "source": [
        "f\"Taille du dataset {len(instance_weights)}, poids total du dataset {instance_weights.sum()}.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0oFO7CzAVkN"
      },
      "source": [
        "Conversion en dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9_8B7pGAVkN"
      },
      "outputs": [],
      "source": [
        "def get_df(MepsDataset):\n",
        "    data = MepsDataset.convert_to_dataframe()\n",
        "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
        "    df = data[0]\n",
        "    df[\"WEIGHT\"] = data[1][\"instance_weights\"]\n",
        "    return df\n",
        "\n",
        "\n",
        "df = get_df(MEPSDataset19_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4WMnAYZAVkN"
      },
      "source": [
        "Nous réalisons maintenant l'opération inverse (qui sera indispensable pour le projet). Créer un objet de la classe StandardDataset de AIF360 à partir du dataframe.\n",
        "\n",
        "Pour le projet cela vous permettre d'utiliser les méthode déjà implémentées dans AIF360 sur votre jeu de données.\n",
        "\n",
        "Ici cela n'a aucun intéret car le dataframe vien d'un StandardDataset, nous vous fournissons le code. Mais cela vaut le coup de le lire attentivement et de poser des questions si besoin.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkJksoOjAVkN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from aif360.datasets import StandardDataset\n",
        "import pandas as pd\n",
        "\n",
        "# Get categorical column from one hot encoding (specitic to MEPSdataset)\n",
        "# Here we create a dictionnary that links each categorical column name\n",
        "# to the list of corresponding one hot encoded columns\n",
        "categorical_columns_dic = {}\n",
        "for col in df.columns:\n",
        "    col_split = col.split(\"=\")\n",
        "    if len(col_split) > 1:\n",
        "        cat_col = col_split[0]\n",
        "        if not (cat_col in categorical_columns_dic.keys()):\n",
        "            categorical_columns_dic[cat_col] = []\n",
        "        categorical_columns_dic[cat_col].append(col)\n",
        "categorical_features = categorical_columns_dic.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjYEWs-aAVkN"
      },
      "outputs": [],
      "source": [
        "# Now we recreate the categorical column value from the one hot encoded\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "def categorical_transform(df, onehotencoded, cat_col):\n",
        "    if len(onehotencoded) > 1:\n",
        "        return df[onehotencoded].apply(\n",
        "            lambda x: onehotencoded[np.argmax(x)][len(cat_col) + 1 :], axis=1\n",
        "        )\n",
        "    else:\n",
        "        return df[onehotencoded]\n",
        "\n",
        "\n",
        "# Reverse the categorical one hot encoded\n",
        "for cat_col, onehotencoded in categorical_columns_dic.items():\n",
        "    df[cat_col] = categorical_transform(df, onehotencoded, cat_col)\n",
        "    df.drop(columns=onehotencoded, inplace=True)\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfFSxUS0AVkN"
      },
      "outputs": [],
      "source": [
        "MyDataset = StandardDataset(\n",
        "    df=df,\n",
        "    label_name=\"UTILIZATION\",\n",
        "    favorable_classes=[1],\n",
        "    protected_attribute_names=[\"RACE\"],\n",
        "    privileged_classes=[[1]],\n",
        "    instance_weights_name=\"WEIGHT\",\n",
        "    categorical_features=categorical_features,\n",
        "    features_to_keep=[],\n",
        "    features_to_drop=[],\n",
        "    na_values=[\"?\", \"Unknown/Invalid\"],\n",
        "    custom_preprocessing=None,\n",
        "    metadata=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTR8bsW8AVkN"
      },
      "outputs": [],
      "source": [
        "# We check the dataset has the same metrics :D\n",
        "# Attention étonnanement le positive label 'favorable_classes' est par défaut 1 (cela est un peu bizarre pour ce dataset)\n",
        "print(\n",
        "    BinaryLabelDatasetMetric(\n",
        "        MEPSDataset19_data,\n",
        "        unprivileged_groups=[{\"RACE\": 0}],\n",
        "        privileged_groups=[{\"RACE\": 1}],\n",
        "    ).disparate_impact(),\n",
        "    BinaryLabelDatasetMetric(\n",
        "        MEPSDataset19_data,\n",
        "        unprivileged_groups=[{\"RACE\": 0}],\n",
        "        privileged_groups=[{\"RACE\": 1}],\n",
        "    ).base_rate(),\n",
        ")\n",
        "print(\n",
        "    BinaryLabelDatasetMetric(\n",
        "        MyDataset, unprivileged_groups=[{\"RACE\": 0}], privileged_groups=[{\"RACE\": 1}]\n",
        "    ).disparate_impact(),\n",
        "    BinaryLabelDatasetMetric(\n",
        "        MyDataset, unprivileged_groups=[{\"RACE\": 0}], privileged_groups=[{\"RACE\": 1}]\n",
        "    ).base_rate(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ28otZ9AVkN"
      },
      "outputs": [],
      "source": [
        "from aif360.sklearn.metrics import disparate_impact_ratio, base_rate\n",
        "\n",
        "dir = disparate_impact_ratio(\n",
        "    y_true=df.UTILIZATION, prot_attr=df.RACE, pos_label=1, sample_weight=df.WEIGHT\n",
        ")\n",
        "br = base_rate(y_true=df.UTILIZATION, pos_label=1, sample_weight=df.WEIGHT)\n",
        "dir, br"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Zbw-U4mTKf"
      },
      "source": [
        "## 2. Appliquer les méthodes de pré-processing disponibles dans AIF360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2G9GokUAVkN"
      },
      "outputs": [],
      "source": [
        "sens_ind = 0\n",
        "sens_attr = dataset_orig_panel19_train.protected_attribute_names[sens_ind]\n",
        "unprivileged_groups = [\n",
        "    {sens_attr: v}\n",
        "    for v in dataset_orig_panel19_train.unprivileged_protected_attributes[sens_ind]\n",
        "]\n",
        "privileged_groups = [\n",
        "    {sens_attr: v}\n",
        "    for v in dataset_orig_panel19_train.privileged_protected_attributes[sens_ind]\n",
        "]\n",
        "sens_attr, unprivileged_groups, privileged_groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibSJ6X7DAVkN"
      },
      "source": [
        "### 2.1 Quesiton: Apprendre une regression logistique qui prédit l'UTILIZATION\n",
        "\n",
        "Attention nous avons enlever le preprocessing sur le dataframe, il faut cette fois utiliser l'API d'AIF360\n",
        "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.StructuredDataset.html\n",
        "\n",
        "pour retrouver les features (X), les labels (y) et les poids de chaque instance du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP8OBN2CAVkN"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0SSilCAVkN"
      },
      "source": [
        "### 2.2 Question: Calcul des métriques de fairness\n",
        "\n",
        "Calculer les métriques du dataset de validation seul.\n",
        "\n",
        "Calculer les métriques basées sur les prédictions et la vérité du dataset de validation.\n",
        "\n",
        "En comparaison calculer les métriques basées sur des prédictions aléatoires et la vérité du dataset de validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DG8_NX_AVkN"
      },
      "outputs": [],
      "source": [
        "print(\"TODO Metrics on validation dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydyQtGxDAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO Metrics based on predictions and truth on validation dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKan1YXFAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO Metrics based on random predictions and truth on validation dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Haix0kTKAVkO"
      },
      "source": [
        "### 2.2 Repondération\n",
        "#### 2.2.1. Question : Trouver dans l'API quels objets/fonctions sont à utiliser pour faire de repondération et les appliquer sur le dataset d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrkxtMgvAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSbOgCdYAVkO"
      },
      "source": [
        "#### 2.2.2. Question: Apprendre une regression logistique sur les données pondérées et calculer les métriques de fairness sur l'échantillon de validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8oTQuuqAVkO"
      },
      "source": [
        "Comme vu en cours le Reweighting ne modifie que la pondération du dataset, les features et label restent inchangés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42EmGC1yAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idpx9JQhAVkO"
      },
      "source": [
        "### 2.3. Disparate Impact Remover\n",
        "#### 2.3.1. Question : Trouver dans l'API quels objets/fonctions sont à utiliser pour faire une approache de disparate impact remover et les appliquer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXdACyilAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0974hphlAVkO"
      },
      "source": [
        "#### 2.3.2. Question: Apprendre une regression logistique sur les données transformées en retirant l'attribut sensible et calculer les métriques de fairness sur l'échantillon de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTRjV4CNAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxu533OnAVkO"
      },
      "source": [
        "### 2.4. Question: Apprentissage de représentation latente fair\n",
        "\n",
        "Apprendre le pre-processing et evaluer son impact avec les métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u6H09m3AVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3VAODJBAVkO"
      },
      "source": [
        "## 3 Post processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgnuqCJXAVkO"
      },
      "source": [
        "### 3.1 Question: Use the post-processing Reject Option Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcWJb5YEAVkO"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV79_o6GAVkO"
      },
      "source": [
        "#### 3.1.1 Reuse the first Logistic Regression learn to find the best threshold that maximises its balanced accuracy on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo6fSOFUAVkU"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHaEP8jeAVkU"
      },
      "source": [
        "#### 3.1.2 Use the RejectOptionClassification  on the validation dataset with the logistic regression predictions. To improve the fairness metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dBtrr-fAVkU"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGeqsseWAVkU"
      },
      "source": [
        "#### 3.1.3 Do the same while starting from the Logistic Regression learned on the Reweighted dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daLpS6iHAVkU"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yGdW4ZvAVkU"
      },
      "source": [
        "#### 3.2 Use the Calibrated Equalised Odds  on the validation dataset with the logistic regression predictions. To improve the fairness metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKzaffI2AVkU"
      },
      "outputs": [],
      "source": [
        "print(\"TODO\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "td3_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
