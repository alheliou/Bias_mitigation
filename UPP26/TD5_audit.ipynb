{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HRe6S30b9Ng7"
   },
   "source": [
    "# TD 5: Audit de modèles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this TD the aim is to analyse the decision made by a model.\n",
    "You will use 3 different methods:\n",
    "- feature importances with LIME\n",
    "- black box auditing that consider the features by couple\n",
    "- counter factual examples with dice-ml\n",
    "\n",
    "## Installation of the environnement\n",
    "\n",
    "We highly recommend you to follow these steps, it will allow every student to work in an environment as similar as possible to the one used during testing.\n",
    "\n",
    "### Colab Settings\n",
    "  The next cell of code are to execute only once per colab environment\n",
    "\n",
    "\n",
    "#### Python env creation\n",
    "\n",
    "        ```\n",
    "        ! python -m pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
    "        ```\n",
    "### Local Settings\n",
    "\n",
    "#### 1. Uv installation\n",
    "\n",
    "\n",
    "        https://docs.astral.sh/uv/getting-started/installation/\n",
    "\n",
    "\n",
    "        `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
    "\n",
    "        Python version 3.12 installation (highly recommended)\n",
    "        `uv python install 3.12`\n",
    "\n",
    "\n",
    "#### 3. Python env creation\n",
    "\n",
    "        ```\n",
    "        mkdir TD_bias_mitigation\n",
    "        cd TD_bias_mitigation\n",
    "        uv python pin 3.12\n",
    "        uv init\n",
    "        uv pip install numpy fairlearn plotly nbformat ipykernel aif360[\"inFairness\"] aif360['AdversarialDebiasing'] causal-learn BlackBoxAuditing cvxpy dice-ml lime shapkit\n",
    "        ```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9c9ITNS89NhA"
   },
   "source": [
    "## Import and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1707145084689,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "88mMZIic9NhB",
    "outputId": "46750ce4-6670-4c2c-bdb7-b4b9ab7c4af1"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", append=True, category=UserWarning)\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "\n",
    "# Fairness metrics\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "MEPSDataset19_data = MEPSDataset19()\n",
    "(dataset_orig_panel19_train, dataset_orig_panel19_val, dataset_orig_panel19_test) = (\n",
    "    MEPSDataset19().split([0.5, 0.8], shuffle=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22874,
     "status": "ok",
     "timestamp": 1707145107555,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "LYbdfIPs9NhE"
   },
   "outputs": [],
   "source": [
    "len(dataset_orig_panel19_train.instance_weights), len(\n",
    "    dataset_orig_panel19_val.instance_weights\n",
    "), len(dataset_orig_panel19_test.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.metrics import *\n",
    "from sklearn.metrics import  balanced_accuracy_score\n",
    "\n",
    " \n",
    "# This method takes lists\n",
    "def get_metrics(\n",
    "    y_true, # list or np.array of truth values\n",
    "    y_pred=None,  # list or np.array of predictions\n",
    "    prot_attr=None, # list or np.array of protected/sensitive attribute values\n",
    "    priv_group=1, # value taken by the privileged group\n",
    "    pos_label=1, # value taken by the positive truth/prediction\n",
    "    sample_weight=None # list or np.array of weights value,\n",
    "):\n",
    "    group_metrics = {}\n",
    "    group_metrics[\"base_rate_truth\"] = base_rate(\n",
    "        y_true=y_true, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"statistical_parity_difference\"] = statistical_parity_difference(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    group_metrics[\"disparate_impact_ratio\"] = disparate_impact_ratio(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "    )\n",
    "    if not y_pred is None:\n",
    "        group_metrics[\"base_rate_preds\"] = base_rate(\n",
    "        y_true=y_pred, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"equal_opportunity_difference\"] = equal_opportunity_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"average_odds_difference\"] = average_odds_difference(\n",
    "            y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, priv_group=priv_group, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        if len(set(y_pred))>1:\n",
    "            group_metrics[\"conditional_demographic_disparity\"] = conditional_demographic_disparity(\n",
    "                y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "            )\n",
    "        else:\n",
    "            group_metrics[\"conditional_demographic_disparity\"] =None\n",
    "        group_metrics[\"smoothed_edf\"] = smoothed_edf(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"df_bias_amplification\"] = df_bias_amplification(\n",
    "        y_true=y_true, y_pred=y_pred, prot_attr=prot_attr, pos_label=pos_label, sample_weight=sample_weight\n",
    "        )\n",
    "        group_metrics[\"balanced_accuracy_score\"] = balanced_accuracy_score(\n",
    "        y_true=y_true, y_pred=y_pred, sample_weight=sample_weight\n",
    "        )\n",
    "    return group_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de LIME\n",
    "### Question 1.1 - apprendre une regression logistique qui prédit l'UTILIZATION (comme dans le TD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X_train = dataset_orig_panel19_train.features\n",
    "y_train = dataset_orig_panel19_train.labels[:,0]\n",
    "X_val = dataset_orig_panel19_val.features\n",
    "y_val = dataset_orig_panel19_val.labels[:,0]\n",
    "\n",
    "\n",
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 (optionelle) - Observer l'impact du threshold sur les performances de la regression logistique (balanced accuracy et disparate impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO optional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 : apprendre un LimeEncoder (nomer l'objet lime_data) sur le dataset AIF360 de train, puis transformer avec ce LimeEncoder le dataset de train et celui de test en s_train et s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets.lime_encoder import LimeEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lime_data = LimeEncoder().fit(\"TOFILL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train = lime_data.transform(\"TOFILL\")\n",
    "s_test = lime_data.transform(\"TOFILL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4 use LimeTabularExplainer to explain the decision made on several instances of the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTabularExplainer(\n",
    "        s_train, \n",
    "        class_names=lime_data.s_class_names, \n",
    "        feature_names=lime_data.s_feature_names,\n",
    "        categorical_features=lime_data.s_categorical_features, \n",
    "        categorical_names=lime_data.s_categorical_names, \n",
    "        kernel_width=3, verbose=False, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_predict_fn(x):\n",
    "    return model.predict_proba(lime_data.inverse_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_explanation(ind):\n",
    "    exp = explainer.explain_instance(s_test[ind], s_predict_fn, num_features=10)\n",
    "    print(\"Actual label: \" + str(dataset_orig_panel19_test.labels[ind]))\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5: Redo the with a regression logistic trained on the Rewieghted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xNnaNQKu9NhF"
   },
   "source": [
    "## Question2 Utilisation de BlackBoxAuditing\n",
    "\n",
    "Attention cette fois, nous nous intéressons aux influences indirectes, cette méthode considères les features par couple.\n",
    "\n",
    "Aussi transformer les attributs catégoriels en \"one hot encoding\", n'est cette fois pas une bonne approche car ces colonnes seront par construction très liées entre elles.\n",
    "\n",
    "Nous allons du coup utiliser un ordinal encoding puis uniquement les classifieurs de sklearn compatible avec les attributs catégoriels ( HistGradientBoostingClassifier).\n",
    "\n",
    "Il faut dans un premier temps transformer le dataset AIF en dataframe et regrouper les colonnes qui ont déjà été one_hot_encodé (tout cela a déja été fait dans le TD3) puis appliqué un ordinal encoding aux colonnes catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1 preprocesser la donnée\n",
    "\n",
    "Afin que vous puissiez passer plus de temps à manipuler les explications, nous vous fournissons le code pour bien formatter le dataframe\n",
    "vous pouvez passer à la 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def get_df(MepsDataset):\n",
    "    data = MepsDataset.convert_to_dataframe()\n",
    "    # data_train est un tuple, avec le data_frame et un dictionnaire avec toutes les infos (poids, attributs sensibles etc)\n",
    "    df = data[0]\n",
    "    df[\"WEIGHT\"] = data[1][\"instance_weights\"]\n",
    "    # Get categorical column from one hot encoding (specitic to MEPSdataset)\n",
    "    # Here we create a dictionnary that links each categorical column name\n",
    "    # to the list of corresponding one hot encoded columns\n",
    "    categorical_columns_dic = {}\n",
    "    for col in df.columns:\n",
    "        col_split = col.split(\"=\")\n",
    "        if len(col_split) > 1:\n",
    "            cat_col = col_split[0]\n",
    "            if not (cat_col in categorical_columns_dic.keys()):\n",
    "                categorical_columns_dic[cat_col] = []\n",
    "            categorical_columns_dic[cat_col].append(col)\n",
    "    categorical_features = categorical_columns_dic.keys()\n",
    "    print(categorical_features)\n",
    "\n",
    "    def categorical_transform(df, onehotencoded, cat_col):\n",
    "        if len(onehotencoded) > 1:\n",
    "            return df[onehotencoded].apply(\n",
    "                lambda x: onehotencoded[np.argmax(x)][len(cat_col) + 1 :], axis=1\n",
    "            )\n",
    "        else:\n",
    "            return df[onehotencoded]\n",
    "\n",
    "\n",
    "    # Reverse the categorical one hot encoded\n",
    "    for cat_col, onehotencoded in categorical_columns_dic.items():\n",
    "        df[cat_col] = categorical_transform(df, onehotencoded, cat_col)\n",
    "        df.drop(columns=onehotencoded, inplace=True)\n",
    "\n",
    "    encoders = {cat_col:preprocessing.LabelEncoder() for cat_col in categorical_features}\n",
    "\n",
    "    for cat_col in categorical_features:\n",
    "        df[cat_col] = encoders[cat_col].fit_transform(df[cat_col])\n",
    "        print(cat_col)\n",
    "        for idx in sorted(df[cat_col].unique()):\n",
    "            print(idx, encoders[cat_col].inverse_transform([idx]))\n",
    "    return df, encoders\n",
    "\n",
    "\n",
    "df, encoders = get_df(MEPSDataset19_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nI0ZWDi_85Oi"
   },
   "source": [
    "### Question 2.2  Separation train/test du dataframe transformé pour BlackBoxAudit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1707147531367,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "0THW5WH238Xn",
    "outputId": "7d81820a-0764-4a12-9f1c-c51e1db3b712"
   },
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qwVAJmpO8-yV"
   },
   "source": [
    "### Question 2.3: Apprentissage d'un modèle HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1707147589219,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "_Te7t7i59NhI",
    "outputId": "1e81deee-47e5-4393-bd59-d40f117d1852"
   },
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B3Zbw-U4mTKf"
   },
   "source": [
    "### Question 2.4 utiliser la librairie BlackBoxAuditing pour \"auditer\" le modèle par l'analyse des influences indirectes de l'age (le calcul prend du temps mais n'hesitez pas à faires d'autres attributs)\n",
    "\n",
    "Le code est de nouveau fournit, vous avez juste à adapter avec vos notations\n",
    "\n",
    "Voici la documentaiton de la librairie utilisée\n",
    "https://github.com/algofairness/BlackBoxAuditing/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1707147598049,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "TqqF108qfkO9"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save your data (name X_test, y_test, X_train, y_train here) and model (named clf here) on disk\n",
    "\n",
    "data_test = X_test.copy(deep=True)\n",
    "data_test[\"Y\"] = y_test\n",
    "\n",
    "data_test.to_csv(\"TD5_test_data.csv\",\n",
    "          index=False)\n",
    "\n",
    "data_train = X_train.copy(deep=True)\n",
    "data_train[\"Y\"] = y_train\n",
    "\n",
    "data_train.to_csv(\"TD5_train_data.csv\",\n",
    "          index=False)\n",
    "\n",
    "with open( 'TD5_clf.pickle', 'wb' ) as f:\n",
    "    pickle.dump(clf, f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 75340,
     "status": "ok",
     "timestamp": 1707147682075,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "ham07j36mm16"
   },
   "outputs": [],
   "source": [
    "from BlackBoxAuditing.data import load_from_file\n",
    "from BlackBoxAuditing.model_factories.AbstractModelFactory import AbstractModelFactory\n",
    "from BlackBoxAuditing.model_factories.AbstractModelVisitor import AbstractModelVisitor\n",
    "\n",
    "import BlackBoxAuditing as BBA\n",
    "\n",
    "\n",
    "(_, train_BBA, _, _, _, _) = load_from_file(\"TD5_train_data.csv\",\n",
    "                      correct_types = [int if col_type==\"int\" else float for col_type in  data_train.dtypes],\n",
    "                                response_header = 'Y',\n",
    "                               train_percentage = 1.0)\n",
    "(headers, _, test_BBA, response_header, features_to_ignore, correct_types) = load_from_file(\"TD5_test_data.csv\",\n",
    "                      correct_types = [int if col_type==\"int\" else float for col_type in  data_test.dtypes],\n",
    "                                response_header = 'Y',\n",
    "                               train_percentage = 0.0)\n",
    "BBA_data = (headers, train_BBA, test_BBA, response_header, features_to_ignore, correct_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1707147682077,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "C8wbMPKrnAYy"
   },
   "outputs": [],
   "source": [
    "class HirePredictorBuilder(AbstractModelFactory):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        AbstractModelFactory.__init__(self, *args, **kwargs)\n",
    "        self.verbose_factory_name = \"HirePredictor\"\n",
    "    def build(self, train_set):\n",
    "        return HirePredictor()\n",
    "\n",
    "class HirePredictor(AbstractModelVisitor):\n",
    "    def __init__(self):\n",
    "        with open( 'TD5_clf.pickle', 'rb' ) as f:\n",
    "            self.clf = pickle.load(f)\n",
    "\n",
    "    def test(self, test_set, test_name=\"\"):\n",
    "        return [[v[-1], self.clf.predict(np.expand_dims(np.array(v[:-1]), axis = 0))] for v in test_set]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1707147682079,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "n7am-Snruh0t"
   },
   "outputs": [],
   "source": [
    "features_to_audit = [\n",
    "    \"AGE\",\n",
    "    \"SEX\",\n",
    "    \"RACE\",\n",
    "    \"REGION\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1410995,
     "status": "ok",
     "timestamp": 1707149093060,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "1j5lPGOinDL8",
    "outputId": "447d78a3-4877-4b75-c166-6cb05ad714e7"
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = HirePredictorBuilder\n",
    "auditor(BBA_data, output_dir = \"audit-output\", features_to_audit=features_to_audit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zEvStY5L9NhZ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.5: If you are curious redo the auditing of a model with bias mitigation approach (for example Reweighing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mADer-oDCHHn"
   },
   "source": [
    "## Question 3: Generer des exemples contrefactuels en utilisant dice-ml\n",
    "\n",
    "Voici la documentation de la librairie utilisée\n",
    "https://github.com/interpretml/DiCE?tab=readme-ov-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 735,
     "status": "ok",
     "timestamp": 1707149615501,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "524Dt_0dC9N_"
   },
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1354,
     "status": "ok",
     "timestamp": 1707149621904,
     "user": {
      "displayName": "Alice H",
      "userId": "13901604971984976961"
     },
     "user_tz": -60
    },
    "id": "RwXSW1zkCsF3"
   },
   "outputs": [],
   "source": [
    "# provide the trained ML model to DiCE's model object\n",
    "# use the HistGradientBoostingClassifier from the BlackBoxAuditiing\n",
    "backend = 'sklearn'\n",
    "m = dice_ml.Model(model=clf, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 : Create a list with all continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 ceate a dice_ml Data with the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3  use dice to create counterfactual example using the 'random' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.4 Redo the counterfactuals creation using only data statistics not the data itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.5: If you are curious redo the counter factual example creation with a model with bias mitigation approach (for example Reweighing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TODO\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "14Gtb6_jB6U1zunonEcL1zmiTvzsljksu",
     "timestamp": 1707144797600
    },
    {
     "file_id": "1reWieE41k1RU9_T08Chmufh9WOwBoIKZ",
     "timestamp": 1706013971768
    },
    {
     "file_id": "1fWzH-WkCZ9xcagC-8OY71_b_aNcXfdpM",
     "timestamp": 1705973751107
    }
   ]
  },
  "kernelspec": {
   "display_name": "env_adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
